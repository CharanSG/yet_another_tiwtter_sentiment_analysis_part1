{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yet Another Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I finished an 11-part series blog posts on Twitter sentiment analysis not long ago. Why do I want to do the sentiment analysis again? I wanted to extend further and run sentiment analysis on real retrieved tweets. And there are other limits to my previous sentiment analysis project.\n",
    "\n",
    "1. The project stopped at the final trained model and lacks application of the model to retrieved tweets\n",
    "2. The model was trained on only positive and negative class, so it lacks the ability to predict a neutral class\n",
    "\n",
    "Regarding neutral class, it might be possible to set a threshold value for negative, neutral, positive class, and map the final output probability value to one of three classes, but I wanted to train a model with training data, which has three sentiment classes: negative, neutral, positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I already wrote quite a lengthy series on NLP, sentiment analysis, if a concept was already covered in my previous posts, I won't go into the detailed explanation. And also the main data visualisation will be with retrieved tweets, and I won't go through extensive data visualisation with the data I use for training and testing a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train my sentiment classifier, I need a dataset which meets conditions below.\n",
    "\n",
    "- Preferably tweets text data with annotated sentiment label\n",
    "- with 3 sentiment classes: negative, neutral, positive\n",
    "- big enough to train a model\n",
    "\n",
    "While googling to find a good data source, I learned about renowned NLP competition called SemEval.\n",
    "\"SemEval (Semantic Evaluation) is an ongoing series of evaluations of computational semantic analysis systems, organized under the umbrella of SIGLEX, the Special Interest Group on the Lexicon of the Association for Computational Linguistics.\"\n",
    "http://alt.qcri.org/semeval2017/\n",
    "You might have already heard of this if you're interested in NLP. Highly-skilled teams from all around the world compete on a couple of tasks such as \"semantic textual similarity\", \"multilingual semantic word similarity\", etc.\n",
    "One of the competition tasks is the Twitter sentiment analysis. It also has a couple of subtasks, but what I would want to focus on is \"Subtask A. : Message Polarity Classification: Given a message, classify whether the message is of positive, negative, or neutral sentiment\".\n",
    "http://alt.qcri.org/semeval2017/task4/\n",
    "\n",
    "Luckily the dataset they provide for the competition is available to download.\n",
    "http://alt.qcri.org/semeval2017/task4/index.php?id=data-and-tools\n",
    "The training data consists of SemEval's previous training and test data. What's even better is they provide test data, and all the teams who participated in the competition are scored with the same test data. This means I can compare my model performance with 2017 participants in SemEval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first downloaded full training data for SemEval 2017 Task 4. http://alt.qcri.org/semeval2017/task4/index.php?id=download-the-full-training-data-for-semeval-2017-task-4\n",
    "\n",
    "There are 11 txt files in total, spanning from SemEval 2013 to SemEval 2016. While trying to read the files into a Pandas dataframe, I found two files cannot be properly loaded as tsv file. It seems like there are some entries not properly tab-separated, so end up as a chunk of 10 or more tweets stuck together. I could have tried retrieving them with tweet ID provided, but I decided to first ignore these two files, and make up a training set with only 9 txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path ='Subtask_A/'\n",
    "all_files = glob.glob(path + \"/twitter*.txt\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in all_files:\n",
    "    df = pd.read_csv(file_,index_col=None, sep='\\t', header=None, names=['id','sentiment','text','to_delete'])\n",
    "    list_.append(df.iloc[:,:-1])\n",
    "df = pd.concat(list_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset looks fairly simple with individual tweet ID, sentiment label, and tweet text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41700</th>\n",
       "      <td>639016598477651968</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@YouAreMyArsenal Wouldn't surprise me if we en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41701</th>\n",
       "      <td>640276909633486849</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41702</th>\n",
       "      <td>640296841725235200</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Noooooo! I was hoping to see Zlatan being Zlat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41703</th>\n",
       "      <td>641017384908779520</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@Fronsoir Zlatan has never done it on a wet Tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41704</th>\n",
       "      <td>641395811474128896</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@ZIatanVines  how many goals Zlatan intends to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id sentiment  \\\n",
       "41700  639016598477651968   neutral   \n",
       "41701  640276909633486849   neutral   \n",
       "41702  640296841725235200   neutral   \n",
       "41703  641017384908779520   neutral   \n",
       "41704  641395811474128896   neutral   \n",
       "\n",
       "                                                    text  \n",
       "41700  @YouAreMyArsenal Wouldn't surprise me if we en...  \n",
       "41701  Rib injury for Zlatan against Russia is a big ...  \n",
       "41702  Noooooo! I was hoping to see Zlatan being Zlat...  \n",
       "41703  @Fronsoir Zlatan has never done it on a wet Tu...  \n",
       "41704  @ZIatanVines  how many goals Zlatan intends to...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41705 entries, 0 to 41704\n",
      "Data columns (total 3 columns):\n",
      "id           41705 non-null int64\n",
      "sentiment    41705 non-null object\n",
      "text         41705 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 977.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total 41,705 tweets. As another sanity check, let's take a look at how many words are there in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_length'] = [len(x.split(\" \")) for x in df.text]\n",
    "max(df.token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NO. 108 UN JORIT MAR DALA ZAYUN                                  (Watchman on the Walls of Zion) Doh is C  1. Un... http://t.co/gNu3AzZ6qH'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.token_length.idxmax(),'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, the token length looks fine, and the tweet for maximum token length seems like a properly parsed tweet. Let's take a look at the class distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     19466\n",
       "positive    15754\n",
       "negative     6485\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is not well balanced, and negative class has the least number of data entries with 6,485, and the neutral class has the most data with 19,466 entries. I want to rebalance the data so that I will have a balanced dataset at least for training. I will deal with this after I define the cleaning function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning process is similar to my previous project, but this time I added a long list of contraction to expand most of the contracted form to its original form such as \"don't\" to \"do not\". And this time, instead of Regex, I used Spacy to parse the documents, and filtered numbers, URL, punctuation, etc. Below are the steps I took to clean the tweets.\n",
    "\n",
    "1. Decoding: unicode_escape for extra \"\\\" before unicode character, then unidecode\n",
    "2. Apostrophe handled: there are two characters people use for contraction. \"’\"(apostrophe) and \"'\"(single quote). If these two symbols are both used for contraction, it will be difficult to detect and properly map the right expanded form. So any \"’\"(apostrophe) is changed to \"'\"(single quote)\n",
    "3. Contraction check: check if there's any contracted form, and replace it with its original form\n",
    "4. Parsing: done with Spacy\n",
    "5. Filtering punctuation, white space, numbers, URL using Spacy methods while keeping the text content of hashtag intact\n",
    "6. Removed @mention\n",
    "7. Lemmatize: lemmatized each token using Spacy method '.lemma_'. Pronouns are kept as they are since Spacy lemmatizer transforms every pronoun to \"-PRON-\"\n",
    "8. Special character removal\n",
    "9. Single syllable token removal\n",
    "10. Spell correction: it is a simple spell correction dealing with repeated characters such as \"sooooo goooood\". If the same character is repeated more than two times, it shortens the repetition to two. For example \"sooooo goooood\" will be transformed as \"soo good\". This is not a perfect solution since even after correction, in case of \"soo\", it is not a correct spelling. But at least it will help to reduce feature space by making \"sooo\", \"soooo\", \"sooooo\" to the same word \"soo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                       \"here's\": \"here is\",\n",
    "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import unidecode\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def spacy_cleaner(text):\n",
    "    try:\n",
    "        decoded = unidecode.unidecode(codecs.decode(text, 'unicode_escape'))\n",
    "    except:\n",
    "        decoded = unidecode.unidecode(text)\n",
    "    apostrophe_handled = re.sub(\"’\", \"'\", decoded)\n",
    "    expanded = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in apostrophe_handled.split(\" \")])\n",
    "    parsed = nlp(expanded)\n",
    "    final_tokens = []\n",
    "    for t in parsed:\n",
    "        if t.is_punct or t.is_space or t.like_num or t.like_url or str(t).startswith('@'):\n",
    "            pass\n",
    "        else:\n",
    "            if t.lemma_ == '-PRON-':\n",
    "                final_tokens.append(str(t))\n",
    "            else:\n",
    "                sc_removed = re.sub(\"[^a-zA-Z]\", '', str(t.lemma_))\n",
    "                if len(sc_removed) > 1:\n",
    "                    final_tokens.append(sc_removed)\n",
    "    joined = ' '.join(final_tokens)\n",
    "    spell_corrected = re.sub(r'(.)\\1+', r'\\1\\1', joined)\n",
    "    return spell_corrected\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK now let's see how this custom cleaner works with tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Picturehouse's, Pink Floyd's, 'Roger Waters: The Walll - opening 29 Sept is now making waves. Watch the trailer on Rolling Stone - look...  \n",
       "1    Order Go Set a Watchman in store or through our website before Tuesday and get it half price! #GSAW @GSAWatchmanBook https://t.co/KET6EGD1an\n",
       "2    If these runway renovations at the airport prevent me from seeing Taylor Swift on Monday, Bad Blood will have a new meaning.                \n",
       "3    If you could ask an onstage interview question at Miss USA tomorrow, what would it be?                                                      \n",
       "4    A portion of book sales from our Harper Lee/Go Set a Watchman release party on Mon. 7/13 will support @CAP_Tulsa and the great work they do.\n",
       "5    Excited to read \"Go Set a Watchman\" on Tuesday.  But can it possibly live up to \"To Kill a Mockingbird?\"  Any opinions?                     \n",
       "6    Watching Miss USA tomorrow JUST to see @TravisGarland perform, I'm obsessed with his voice                                                  \n",
       "7    Tune-in for the 2015 MISS USA Pageant on ReelzChannel on Sunday, July 12 at 8p ET/5p PT. Contestants from all 50... http://t.co/M3kJowOvQ1  \n",
       "8    Call for reservations for lunch or dinner tomorrow (yep Sunday!). Happy to accommodate guests in town for the MISS USA Pageant 346-5100     \n",
       "9    Miss Universe Org prez tells me #Trump won't attend Sunday's Miss USA event He's missed some in the past, but he said recently he'd be here \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['picturehouse pink floyd roger waters the wall open sept be now make wave watch the trailer on rolling stone look',\n",
       " 'order go set watchman in store or through our website before tuesday and get it half price gsaw',\n",
       " 'if these runway renovation at the airport prevent me from see taylor swift on monday bad blood will have new meaning',\n",
       " 'if you could ask an onstage interview question at miss usa tomorrow what would it be',\n",
       " 'portion of book sale from our harper lee go set watchman release party on mon will support and the great work they do',\n",
       " 'excited to read go set watchman on tuesday but can it possibly live up to to kill mockingbird any opinion',\n",
       " 'watch miss usa tomorrow just to see perform I be obsess with his voice',\n",
       " 'tune in for the miss usa pageant on reelzchannel on sunday july at etp pt contestant from all',\n",
       " 'call for reservation for lunch or dinner tomorrow yep sunday happy to accommodate guest in town for the miss usa pageant',\n",
       " 'miss universe org prez tell me trump will not attend sunday miss usa event He be miss some in the past but he say recently he would be here']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[spacy_cleaner(t) for t in df.text[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it's doing what I intended it to do. I'll clean the \"text\" column and create a new column called \"clean_text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\m'\n",
      "  if __name__ == '__main__':\n",
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\o'\n",
      "  if __name__ == '__main__':\n",
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\,'\n",
      "  if __name__ == '__main__':\n",
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\l'\n",
      "  if __name__ == '__main__':\n",
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\_'\n",
      "  if __name__ == '__main__':\n",
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\/'\n",
      "  if __name__ == '__main__':\n",
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  if __name__ == '__main__':\n",
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\('\n",
      "  if __name__ == '__main__':\n",
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\i'\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df['clean_text'] = [spacy_cleaner(t) for t in df.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the cleaning function I can see it encountered some \"invalid escape sequence\". Let's see what these are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064 @TheMetalCore Can't wait for them both! September is equally impressive with FFDP, Iron Maiden, Slayer, BMTH, and Parkway Drive! \\m/\n",
      "5486 Tomorrow is a big Metal day.  At 8:00am the new Iron Maiden tune premiers and, of course, new albums to purchase.  I love Heavy Metal! \\m/\n",
      "6009 Iron Maiden released their new video on the 14th of august \\m/\n",
      "6234 Check out the new Iron Maiden Video from their forthcoming album Book of Souls out September 4th! \\m/ Listen to... http://t.co/pVDxR2iyQX\n",
      "9836 Another great preview from the new IRON MAIDEN album THE BOOK OF SOULS \\m/ OUT SEPTEMBER 4th http://t.co/sxrPyjyhMH\n",
      "11816 Let's hope it's not!! Look for \"The Book of Souls\" from Iron Maiden This Friday September 4th!! \\m/\\m/ Listen to... http://t.co/R39jz4rmER\n",
      "12008 @TonyBasilio Iron Maiden reference... Now you're talking! New album #BookOfSouls drops Friday #uptheirons  Woooooo! \\m/ \\m/\n",
      "12136 I may be 30 years too late to say this but The Trooper by Iron Maiden is fucking great, For some reason Id never heard it before \\m/\n",
      "12508 @q_salazar well, yeah, but so are you, ese. Oh, and Iron Maiden's new one drops tomorrow! \\m/\n",
      "14487 The new Iron Maiden album for those that may be interested, need another listen but I like it so far :) \\m/\n",
      "23365 Epic!  Judas Priest - Hell Patrol [British Steel 30th Anniversary HD] https://t.co/DIWKuHm9 my top fav song from Painkiller \\m/ love it\n",
      "24181 Lamb of God is coming to town on the 12th!!!!!!!!!!!!!!!! #omg I\\u2019m soooo excited XD I can\\u2019t wait to get into the pit and go crazy! \\m/\n",
      "33652 @iamdavebriggs see you in Manila on Sept  18! Check this out! One of my shots from Smash Project in Manila! \\m/ http://t.co/SMxPUrwk\n",
      "39257 Carnival tomorrow. Then going to mcdonalds with Deztanee and Sam after. \\m/\n",
      "39699 @garrettmaine Garrett\\u002c you are awesome and it was so cool talking to you tonight! David Bowie forever \\m/ See you tomorrow\\u002c hombre.\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(df.text):\n",
    "    if '\\m' in t:\n",
    "        print(i,t)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets that contain '\\m' were actually containing an emoticon '\\m/' I didn't know about this until I googled it. Apparently '\\m/' stands for the horn sign you make with your hand. This hand sign is popular in metal music.\n",
    "https://www.urbandictionary.com/define.php?term=%5Cm%2F\n",
    "Anyway, this is just a warning and it is not an error. Let's see how the cleaner deals with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@TheMetalCore Can't wait for them both! September is equally impressive with FFDP, Iron Maiden, Slayer, BMTH, and Parkway Drive! \\\\m/\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[2064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: invalid escape sequence '\\m'\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'can not wait for them both september be equally impressive with ffdp iron maiden slayer bmth and parkway drive'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_cleaner(df.text[2064])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again it seems like to be doing what I intended it to do. So far so good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The class imbalance problem typically occurs when, in a classification problem, there are many more instances of some classes than others. In such cases, standard classifiers tend to be overwhelmed by the large classes and ignore the small ones.\"\n",
    "https://www3.nd.edu/~dial/publications/chawla2004editorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I have already realised, the training data is not perfectly balanced, 'neutral' class has 3 times more data than 'negative' class, and 'positive' class has around 2.4 times more data than 'negative' class. I will try fitting a model with three different data; oversampled, downsampled, original, to see how different sampling techniques affect the learning of a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple default classifier I'll use to compare performances of different datasets will be the logistic regression. From my previous sentiment analysis project, I learned that Tf-Idf with Logistic Regression is a pretty powerful combination. Before I apply any other more complex models such as ANN, CNN, RNN etc, the performances with logistic regression will hopefully give me a good idea of which data sampling methods I should choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of validation, I will use K-Fold Cross Validation. In my previous project, I split the data into three; training, validation, test, and all the parameter tuning was done with reserved validation set and finally applied the model to the test set. Considering that I had more than 1 million data for training, this kind of validation set approach was acceptable.\n",
    "But this time, the data I have is much smaller (around 40,000 tweets), and by leaving out validation set from the data we might leave out interesting information about data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1, 3))\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def lr_cv(splits, X, Y, pipeline, average_method):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=777)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    for train, test in kfold.split(X, Y):\n",
    "        lr_fit = pipeline.fit(X[train], Y[train])\n",
    "        prediction = lr_fit.predict(X[test])\n",
    "        scores = lr_fit.score(X[test],Y[test])\n",
    "        \n",
    "        accuracy.append(scores * 100)\n",
    "        precision.append(precision_score(Y[test], prediction, average=average_method)*100)\n",
    "        print('              negative    neutral     positive')\n",
    "        print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "        recall.append(recall_score(Y[test], prediction, average=average_method)*100)\n",
    "        print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "        f1.append(f1_score(Y[test], prediction, average=average_method)*100)\n",
    "        print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "        print('-'*50)\n",
    "\n",
    "    print(\"accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "    print(\"precision: %.2f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "    print(\"recall: %.2f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "    print(\"f1 score: %.2f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "original_pipeline = Pipeline([\n",
    "    ('vectorizer', tvec),\n",
    "    ('classifier', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    neutral     positive\n",
      "precision: [ 0.63502455  0.6404264   0.72134595]\n",
      "recall:    [ 0.29915189  0.80225989  0.65312599]\n",
      "f1 score:  [ 0.4067086   0.7122663   0.68554297]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.6486014   0.64023012  0.7088215 ]\n",
      "recall:    [ 0.28604472  0.80041099  0.65280863]\n",
      "f1 score:  [ 0.39700375  0.71141553  0.67966298]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.61661342  0.63999173  0.70892671]\n",
      "recall:    [ 0.29760987  0.7950167   0.64773088]\n",
      "f1 score:  [ 0.40145606  0.70913048  0.67694859]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.64332248  0.63920279  0.70034965]\n",
      "recall:    [ 0.30454896  0.79912664  0.63567122]\n",
      "f1 score:  [ 0.41339613  0.71027397  0.66644485]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.65420561  0.64275407  0.72110994]\n",
      "recall:    [ 0.32382421  0.80092474  0.65174603]\n",
      "f1 score:  [ 0.433213    0.71317475  0.68467567]\n",
      "--------------------------------------------------\n",
      "accuracy: 66.51% (+/- 0.36%)\n",
      "precision: 66.41% (+/- 0.58%)\n",
      "recall: 58.33% (+/- 0.48%)\n",
      "f1 score: 60.01% (+/- 0.55%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5, df.clean_text, df.sentiment, original_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With data as it is without any resampling, we can see that the precision is higher than the recall. If we take a closer look at the result from each fold, we can also see that the recall for the negative class is quite low around 28~30%, while the precisions for the negative class are high as 61~65%. This means the classifier is very picky and does not think many things are negative. All the text it classifies as negative is 61~65% of the time really negative. However, it also misses a lot of actual negative class, because it is so very picky. We have a low recall, but a very high precision. The intuition behind this precision and recall has been taken from a Medium blog post by Andreas Klintberg.\n",
    "https://medium.com/@klintcho/explaining-precision-and-recall-c770eb9c69e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a very useful Python package called \"imbalanced-learn\", which helps you deal with class imbalance issues, it is compatible with Scikit Learn, and easy to implement.\n",
    "https://github.com/scikit-learn-contrib/imbalanced-learn\n",
    "\n",
    "Within imbalanced-learn, there are different techniques you can use for oversampling. I will use below two.\n",
    "\n",
    "1. RandomOverSampler\n",
    "2. SMOTE (Synthetic Minority Over-Sampling Technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one more point to consider if you are cross-validating with oversampled data. Oversampling the minority class can result in overfitting problems if we oversample before cross-validating. Why is that so? Because by oversampling before cross validation split, you are leaking the information of validation data already to your training set. As they say \"What has been seen, cannot be unseen.\" \n",
    "\n",
    "If you want more detailed explanation, I recommed this Youtube video \"Machine Learning - Over-& Undersampling - Python/ Scikit/ Scikit-Imblearn\" https://youtu.be/DQC_YE3I5ig\n",
    "\n",
    "Luckily cross-validation function I defined above as \"lr_cv()\" will fit the pipeline only with the training set split after cross-validation split, thus it is not leaking any information of validation set to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random over-sampling is simply a process of repeating some samples of the minority class and balance the number of samples between classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "\n",
    "ROS_pipeline = make_pipeline(tvec, RandomOverSampler(random_state=777),lr)\n",
    "SMOTE_pipeline = make_pipeline(tvec, SMOTE(random_state=777),lr)\n",
    "ADASYN_pipeline = make_pipeline(tvec, ADASYN(ratio='minority',random_state=777),lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we fit each pipeline, let's see what the RadomOverSampler does. In order to make it easier to see I defined some toy text data below, and the target sentiment value for each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"I love dogs\"\n",
    "sent2 = \"I don't like dogs\"\n",
    "sent3 = \"I adore cats\"\n",
    "sent4 = \"I hate spiders\"\n",
    "sent5 = \"I like dogs\"\n",
    "testing_text = pd.Series([sent1, sent2, sent3, sent4, sent5])\n",
    "testing_target = pd.Series([1,0,1,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My toy data has 5 entries in total, and the target sentiments are three positives and two negatives. In order to be balanced, this toy data needs one more entry of negative class.\n",
    "\n",
    "One thing is over sampler won't be able to handle raw text data. It has to be transformed into a feature space for over sampler to work. I'll first fit TfidfVectorizer, and oversample using Tf-Idf representation of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(stop_words=None, max_features=100000)\n",
    "testing_tfidf = tv.fit_transform(testing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=777)\n",
    "X_ROS, y_ROS = ros.fit_sample(testing_tfidf, testing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adore      cats      dogs       don      hate      like      love  \\\n",
       "0  0.000000  0.000000  0.556451  0.000000  0.000000  0.000000  0.830881   \n",
       "1  0.000000  0.000000  0.462208  0.690159  0.000000  0.556816  0.000000   \n",
       "2  0.707107  0.707107  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.638711  0.000000  0.000000  0.769447  0.000000   \n",
       "\n",
       "    spiders  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.707107  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testing_tfidf.todense(), columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adore      cats      dogs       don      hate      like      love  \\\n",
       "0  0.000000  0.000000  0.556451  0.000000  0.000000  0.000000  0.830881   \n",
       "1  0.000000  0.000000  0.462208  0.690159  0.000000  0.556816  0.000000   \n",
       "2  0.707107  0.707107  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.638711  0.000000  0.000000  0.769447  0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "\n",
       "    spiders  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.707107  \n",
       "4  0.000000  \n",
       "5  0.707107  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_ROS.todense(), columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running RandomOverSampler, now we have one more entry at the end. The last entry added by RandomOverSampler is exactly same as the fourth one (index number 3) from the top. RandomOverSampler simply repeats some entries of the minority class to balance the data. If we look at the target sentiments after RandomOverSampler, we can see that it has now a perfect balance between classes by adding on more entry of negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    neutral     positive\n",
      "precision: [ 0.48110547  0.70700816  0.71385942]\n",
      "recall:    [ 0.65767155  0.64509502  0.68327515]\n",
      "f1 score:  [ 0.55570033  0.67463408  0.69823253]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.48863636  0.70156028  0.70451571]\n",
      "recall:    [ 0.66306862  0.63524274  0.68327515]\n",
      "f1 score:  [ 0.56264311  0.66675654  0.69373288]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.47527004  0.69661675  0.71034946]\n",
      "recall:    [ 0.64456438  0.64526072  0.67089813]\n",
      "f1 score:  [ 0.54712042  0.66995599  0.69006039]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.49520045  0.70120753  0.7072117 ]\n",
      "recall:    [ 0.67617579  0.64140765  0.67534116]\n",
      "f1 score:  [ 0.57170795  0.66997585  0.69090909]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.48336153  0.70673344  0.720148  ]\n",
      "recall:    [ 0.66075559  0.65245312  0.67968254]\n",
      "f1 score:  [ 0.55830619  0.67850942  0.69933039]\n",
      "--------------------------------------------------\n",
      "accuracy: 65.95% (+/- 0.31%)\n",
      "precision: 63.29% (+/- 0.32%)\n",
      "recall: 66.09% (+/- 0.40%)\n",
      "f1 score: 64.18% (+/- 0.34%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5, df.clean_text, df.sentiment, ROS_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the model built with original imbalanced data, now the model behaves in opposite way. The precisions for the negative class are around 47~49%, but the recalls are way higher at 64~67%. Now we have a situation of high recall, low precision. What this means is that the classifier thinks a lot of things are negative. However, it also thinks a lot of non-negative texts are negative. So from our set of data we got a lot of texts classified as negative, many of them were in the set of actual negative, however, a lot of them were also non-negative.\n",
    "\n",
    "But if I consider that without resampling, the recall rate was as low as 28~30% for negative class, the precision rate for the negative class I get from oversampling is more robust at around 47~49%.\n",
    "\n",
    "Another way to look at it is to look at the f1 score, which is the harmonic average of precision and recall. The original imbalanced data had 66.51% accuracy and 60.01% F1 score. However  with oversampling, we get a slightly lower accuracy of 65.95%, but a much higher F1 score of 64.18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE (Synthetic Minority Over-Sampling Technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE is an over-sampling approach in which the minority class is over-sampled by creating\n",
    "“synthetic” examples rather than by over-sampling with replacement.\n",
    "\n",
    "According to the original research paper \"SMOTE: Synthetic Minority Over-sampling Technique\" (Chawla et al., 2002),\n",
    "\"synthetic samples are generated in the following way: Take the difference between the feature vector (sample)\n",
    "under consideration and its nearest neighbour. Multiply this difference by a random number\n",
    "between 0 and 1, and add it to the feature vector under consideration. This causes the\n",
    "selection of a random point along the line segment between two specific features. This\n",
    "approach effectively forces the decision region of the minority class to become more general.\"\n",
    "What this means is that when SMOTE creates a new synthetic data, it will choose one data to copy, and look at its k nearest neighbours. Then, on feature space, it will create random values in feature space that is between the original sample and its neighbours.\n",
    "\n",
    "Once you see the example with the toy data, it will become clearer.\n",
    "https://www.jair.org/media/953/live-953-2037-jair.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298794</td>\n",
       "      <td>0.446153</td>\n",
       "      <td>0.249998</td>\n",
       "      <td>0.359954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adore      cats      dogs       don      hate      like      love  \\\n",
       "0  0.000000  0.000000  0.556451  0.000000  0.000000  0.000000  0.830881   \n",
       "1  0.000000  0.000000  0.462208  0.690159  0.000000  0.556816  0.000000   \n",
       "2  0.707107  0.707107  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.638711  0.000000  0.000000  0.769447  0.000000   \n",
       "5  0.000000  0.000000  0.298794  0.446153  0.249998  0.359954  0.000000   \n",
       "\n",
       "    spiders  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.707107  \n",
       "4  0.000000  \n",
       "5  0.249998  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smt = SMOTE(random_state=777, k_neighbors=1)\n",
    "X_SMOTE, y_SMOTE = smt.fit_sample(testing_tfidf, testing_target)\n",
    "pd.DataFrame(X_SMOTE.todense(), columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last entry is the data created by SMOTE. To make it easier to see, let's see only the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298794</td>\n",
       "      <td>0.446153</td>\n",
       "      <td>0.249998</td>\n",
       "      <td>0.359954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adore  cats      dogs       don      hate      like  love   spiders\n",
       "0  0.0    0.0   0.462208  0.690159  0.000000  0.556816  0.0   0.000000\n",
       "1  0.0    0.0   0.000000  0.000000  0.707107  0.000000  0.0   0.707107\n",
       "2  0.0    0.0   0.298794  0.446153  0.249998  0.359954  0.0   0.249998"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_SMOTE.todense()[y_SMOTE == 0], columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top two entries are original data, and the one on the bottom is synthetic data. You can see it didn't just repeat original data. Instead, the Tf-Idf values are created by taking random values between the top two original data. As you can see, if the Tf-Idf values for both original data are 0, then synthetic data also has 0 for those features, such as \"adore\", \"cactus\", \"cats\", because if two values are the same there are no random values between them. I specifically defined k_neighbors as 1 for this toy data, since there are only two entries of negative class, if SMOTE chooses one to copy, then only one other negative entry left as a neighbour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit the SMOTE pipeline to see how it affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    neutral     positive\n",
      "precision: [ 0.48556582  0.69869842  0.71257086]\n",
      "recall:    [ 0.64841943  0.64791988  0.6781974 ]\n",
      "f1 score:  [ 0.55529878  0.67235177  0.69495935]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.50204559  0.70444444  0.70825083]\n",
      "recall:    [ 0.66229761  0.65142564  0.68105363]\n",
      "f1 score:  [ 0.57114362  0.67689844  0.69438602]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.47701149  0.69521967  0.70925553]\n",
      "recall:    [ 0.63993832  0.64628821  0.67121549]\n",
      "f1 score:  [ 0.54659203  0.66986155  0.6897114 ]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.49440189  0.69782189  0.70401061]\n",
      "recall:    [ 0.64687741  0.65014128  0.67407172]\n",
      "f1 score:  [ 0.56045424  0.6731383   0.68871595]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.48886351  0.70323294  0.72020202]\n",
      "recall:    [ 0.65998458  0.65373748  0.67904762]\n",
      "f1 score:  [ 0.56167979  0.67758253  0.69901961]\n",
      "--------------------------------------------------\n",
      "accuracy: 66.03% (+/- 0.36%)\n",
      "precision: 63.34% (+/- 0.40%)\n",
      "recall: 65.94% (+/- 0.47%)\n",
      "f1 score: 64.21% (+/- 0.43%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5, df.clean_text, df.sentiment, SMOTE_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE sampling seems to have a slightly higher accuracy and F1 score compared to random oversampling. With the results so far, it seems like choosing SMOTE oversampling is preferable over original or random oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about downsampling. If we oversample the minority class in the above oversampling, with downsampling, we try to reduce the data of majority class, so that the data classes are balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "RUS_pipeline = make_pipeline(tvec, RandomUnderSampler(random_state=777),lr)\n",
    "NM1_pipeline = make_pipeline(tvec, NearMiss(ratio='not minority',random_state=777, version = 1),lr)\n",
    "NM2_pipeline = make_pipeline(tvec, NearMiss(ratio='not minority',random_state=777, version = 2),lr)\n",
    "NM3_pipeline = make_pipeline(tvec, NearMiss(ratio=nm3_dict,random_state=777, version = 3, n_neighbors_ver3=4),lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, before we run the pipeline, let's apply this to the toy data to see what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adore      cats      dogs       don      hate      like      love  \\\n",
       "0  0.000000  0.000000  0.462208  0.690159  0.000000  0.556816  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.556451  0.000000  0.000000  0.000000  0.830881   \n",
       "3  0.707107  0.707107  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    spiders  \n",
       "0  0.000000  \n",
       "1  0.707107  \n",
       "2  0.000000  \n",
       "3  0.000000  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=777)\n",
    "X_RUS, y_RUS = rus.fit_sample(testing_tfidf, testing_target)\n",
    "pd.DataFrame(X_RUS.todense(), columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adore      cats      dogs       don      hate      like      love  \\\n",
       "0  0.000000  0.000000  0.556451  0.000000  0.000000  0.000000  0.830881   \n",
       "1  0.000000  0.000000  0.462208  0.690159  0.000000  0.556816  0.000000   \n",
       "2  0.707107  0.707107  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.638711  0.000000  0.000000  0.769447  0.000000   \n",
       "\n",
       "    spiders  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.707107  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testing_tfidf.todense(), columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with the original imbalanced data, we can see that downsampled data has one less entry, which is the last entry of the original data belonging to the positive class. RandomUnderSampler reduces the majority class by randomly removing data from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    neutral     positive\n",
      "precision: [ 0.41158668  0.69661458  0.68481569]\n",
      "recall:    [ 0.73400154  0.54956343  0.64265313]\n",
      "f1 score:  [ 0.52742382  0.61441286  0.66306483]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.42551293  0.69652534  0.68636057]\n",
      "recall:    [ 0.73554356  0.56126381  0.645192  ]\n",
      "f1 score:  [ 0.53913535  0.62162162  0.66513987]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.41437177  0.70032468  0.69186244]\n",
      "recall:    [ 0.74248265  0.55407141  0.64487464]\n",
      "f1 score:  [ 0.53189727  0.61867202  0.66754271]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.4228039   0.69333333  0.69424583]\n",
      "recall:    [ 0.73477255  0.56100694  0.64709616]\n",
      "f1 score:  [ 0.53675021  0.62019026  0.66984231]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.41475054  0.70563056  0.68679119]\n",
      "recall:    [ 0.73708558  0.55047521  0.65365079]\n",
      "f1 score:  [ 0.53081621  0.61847042  0.66981132]\n",
      "--------------------------------------------------\n",
      "accuracy: 61.80% (+/- 0.25%)\n",
      "precision: 60.17% (+/- 0.21%)\n",
      "recall: 64.62% (+/- 0.21%)\n",
      "f1 score: 60.63% (+/- 0.26%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5, df.clean_text, df.sentiment, RUS_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the accuracy and the F1 score has significantly dropped. But the characteristic of low precision and high recall is as same as oversampled data. Only its overall performance dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearMiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the documentation of \"imbalanced-learn\",\n",
    "\"NearMiss adds some heuristic rules to select samples. NearMiss implements 3 different types of heuristic which can be selected with the parameter version. NearMiss heuristic rules are based on nearest neighbors algorithm.\"\n",
    "http://contrib.scikit-learn.org/imbalanced-learn/stable/under_sampling.html#controlled-under-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a good paper on resampling techniques. \"Survey of resampling techniques for improving classification performance in unbalanced datasets\" (Ajinkya More, 2016)\n",
    "https://arxiv.org/pdf/1608.06048.pdf\n",
    "\n",
    "I borrowed the explanation of three different versions of NearMiss from More's paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NearMiss-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NearMiss-1, those points from majority class are retained whose mean distance to the k nearest points in minority class is lowest. Which means it will keep the points of majority class that's similar to the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adore  cats      dogs       don      hate      like      love   spiders\n",
       "0  0.0    0.0   0.462208  0.690159  0.000000  0.556816  0.000000  0.000000\n",
       "1  0.0    0.0   0.000000  0.000000  0.707107  0.000000  0.000000  0.707107\n",
       "2  0.0    0.0   0.638711  0.000000  0.000000  0.769447  0.000000  0.000000\n",
       "3  0.0    0.0   0.556451  0.000000  0.000000  0.000000  0.830881  0.000000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm = NearMiss(ratio='not minority',random_state=777, version=1, n_neighbors=1)\n",
    "X_nm, y_nm = nm.fit_sample(testing_tfidf, testing_target)\n",
    "pd.DataFrame(X_nm.todense(), columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adore      cats      dogs       don      hate      like      love  \\\n",
       "0  0.000000  0.000000  0.556451  0.000000  0.000000  0.000000  0.830881   \n",
       "1  0.000000  0.000000  0.462208  0.690159  0.000000  0.556816  0.000000   \n",
       "2  0.707107  0.707107  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.638711  0.000000  0.000000  0.769447  0.000000   \n",
       "\n",
       "    spiders  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.707107  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testing_tfidf.todense(), columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that NearMiss-1 has eliminated the entry for the text \"I adore cats\", which makes sense because both words \"adore\" and \"cats\" are only appeared in this entry, so makes it the most different from minority class in terms of Tf-Idf representation in feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    neutral     positive\n",
      "precision: [ 0.395671    0.69915254  0.6578125 ]\n",
      "recall:    [ 0.70470316  0.50847458  0.66804189]\n",
      "f1 score:  [ 0.50679235  0.58876004  0.66288773]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.39861051  0.69971264  0.65304241]\n",
      "recall:    [ 0.7077872   0.50038531  0.67438908]\n",
      "f1 score:  [ 0.51        0.58349558  0.66354411]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.39939157  0.71075581  0.6560219 ]\n",
      "recall:    [ 0.70855821  0.50244028  0.68454459]\n",
      "f1 score:  [ 0.51083936  0.58871332  0.66997981]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.4         0.70036364  0.65333734]\n",
      "recall:    [ 0.69853508  0.49473414  0.68962234]\n",
      "f1 score:  [ 0.50870298  0.5798585   0.67098966]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.39974511  0.70746374  0.66476733]\n",
      "recall:    [ 0.72552043  0.51374261  0.66666667]\n",
      "f1 score:  [ 0.51547521  0.5952381   0.66571564]\n",
      "--------------------------------------------------\n",
      "accuracy: 60.11% (+/- 0.24%)\n",
      "precision: 58.64% (+/- 0.28%)\n",
      "recall: 62.99% (+/- 0.32%)\n",
      "f1 score: 58.81% (+/- 0.25%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5, df.clean_text, df.sentiment, NM1_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like both the accuracy and F1 score got worse than random undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NearMiss-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to NearMiss-1, NearMiss-2 keeps those points from the majority class whose mean distance to the k farthest points in minority class is lowest. In other words, it will keep the points of majority class that's most different to the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adore      cats      dogs       don      hate      like      love  \\\n",
       "0  0.000000  0.000000  0.462208  0.690159  0.000000  0.556816  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.556451  0.000000  0.000000  0.000000  0.830881   \n",
       "3  0.707107  0.707107  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    spiders  \n",
       "0  0.000000  \n",
       "1  0.707107  \n",
       "2  0.000000  \n",
       "3  0.000000  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm = NearMiss(ratio='not minority',random_state=777, version=2, n_neighbors=1)\n",
    "X_nm, y_nm = nm.fit_sample(testing_tfidf, testing_target)\n",
    "pd.DataFrame(X_nm.todense(), columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adore</th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "      <th>don</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>spiders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adore      cats      dogs       don      hate      like      love  \\\n",
       "0  0.000000  0.000000  0.556451  0.000000  0.000000  0.000000  0.830881   \n",
       "1  0.000000  0.000000  0.462208  0.690159  0.000000  0.556816  0.000000   \n",
       "2  0.707107  0.707107  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.638711  0.000000  0.000000  0.769447  0.000000   \n",
       "\n",
       "    spiders  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.707107  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testing_tfidf.todense(), columns=tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that NearMiss-2 has eliminated the entry for the text \"I like dogs\", which again makes sense because we also have a negative entry \"I don't like dogs\". Two entries are in different classes but they share two same tokens \"like\" and \"dogs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    neutral     positive\n",
      "precision: [ 0.30916717  0.70748299  0.65716225]\n",
      "recall:    [ 0.79568234  0.37390858  0.61440812]\n",
      "f1 score:  [ 0.44530744  0.48924731  0.63506643]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.36363636  0.70122832  0.67787115]\n",
      "recall:    [ 0.7617579   0.49858721  0.61440812]\n",
      "f1 score:  [ 0.49227703  0.58279538  0.64458132]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.35180364  0.68459838  0.672226  ]\n",
      "recall:    [ 0.72937548  0.47726689  0.62678515]\n",
      "f1 score:  [ 0.47466131  0.56243378  0.64871079]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.34680382  0.67931281  0.68176991]\n",
      "recall:    [ 0.72783346  0.48754174  0.61123453]\n",
      "f1 score:  [ 0.4697686   0.56766861  0.64457831]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.37382075  0.69340404  0.69809284]\n",
      "recall:    [ 0.73323053  0.53737478  0.61587302]\n",
      "f1 score:  [ 0.49518355  0.60549928  0.65441052]\n",
      "--------------------------------------------------\n",
      "accuracy: 57.11% (+/- 2.24%)\n",
      "precision: 57.32% (+/- 1.05%)\n",
      "recall: 61.37% (+/- 1.22%)\n",
      "f1 score: 56.08% (+/- 2.08%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5, df.clean_text, df.sentiment, NM2_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both accuracy and F1 score got even lower compared to NearMiss-1. And we can also see that all the metrics fluctuate from fold to fold quite a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NearMiss-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final NearMiss variant, NearMiss-3 selects k nearest neighbours in majority class for every point in the minority class. In this case, the undersampling ratio is directly controlled by k. For example, if we set k to be 4, then NearMiss-3 will choose 4 nearest neighbours of every minority class entry.\n",
    "\n",
    "Then we'll end up with either more or fewer samples of majority class than minority class depending on n neighbours we set. For example, with my dataset, if I run NearMiss-3 with default n_neighbors_ver3 of 3, it will complain and the number of neutral class(which is majority class in my dataset) will be smaller than negative class(which is minority class in my dataset). So I explicitly set n_neighbors_ver3 to be 4, so that I'll have enough majority class data at least the same number as the minority class.\n",
    "\n",
    "One thing I'm not completely sure is that what kind of filtering it applies when all the data selected with n_neighbors_ver3 parameter is more than the minority class. As you will see below, after applying NearMiss-3, the dataset is perfectly balanced. However, if the algorithm simply chooses the nearest neighbour according to the n_neighbors_ver3 parameter, I doubt that it will end up with the exact same number of entries for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    neutral     positive\n",
      "precision: [ 0.41911765  0.69426121  0.66879387]\n",
      "recall:    [ 0.70316114  0.54057524  0.66518566]\n",
      "f1 score:  [ 0.52519436  0.60785446  0.66698488]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.44198895  0.69118148  0.6331673 ]\n",
      "recall:    [ 0.67848882  0.52144875  0.68581403]\n",
      "f1 score:  [ 0.53527981  0.59443631  0.65843998]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.43694141  0.69058143  0.63880685]\n",
      "recall:    [ 0.67848882  0.52170563  0.68644875]\n",
      "f1 score:  [ 0.53156146  0.59438104  0.66177145]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.43076923  0.68832848  0.66226233]\n",
      "recall:    [ 0.71241326  0.54687901  0.65217391]\n",
      "f1 score:  [ 0.53689715  0.60950472  0.65717941]\n",
      "--------------------------------------------------\n",
      "              negative    neutral     positive\n",
      "precision: [ 0.45201238  0.68896321  0.63042204]\n",
      "recall:    [ 0.67540478  0.52915489  0.68285714]\n",
      "f1 score:  [ 0.54157651  0.5985762   0.65559281]\n",
      "--------------------------------------------------\n",
      "accuracy: 61.03% (+/- 0.20%)\n",
      "precision: 59.12% (+/- 0.23%)\n",
      "recall: 63.20% (+/- 0.39%)\n",
      "f1 score: 59.83% (+/- 0.21%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5, df.clean_text, df.sentiment, NM3_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NearMiss-3 produced the most robust result within NearMiss family, but slightly lower than RandomUnderSampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution before NearMiss-3: Counter({'neutral': 19466, 'positive': 15754, 'negative': 6485})\n",
      "Distribution after NearMiss-3: Counter({'negative': 6485, 'neutral': 6485, 'positive': 6485})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "nm3 = NearMiss(ratio='not minority',random_state=777, version=3, n_neighbors_ver3=4)\n",
    "tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1, 3))\n",
    "df_tfidf = tvec.fit_transform(df.clean_text)\n",
    "X_res, y_res = nm3.fit_sample(df_tfidf, df.sentiment)\n",
    "print('Distribution before NearMiss-3: {}'.format(Counter(df.sentiment)))\n",
    "print('Distribution after NearMiss-3: {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5-fold cross validation result**\n",
    "*(classifier used for validation: logistic regression with default setting)*\n",
    "\n",
    "|            | accuracy | macro average precision | macro average recall | macro average f1 score     |\n",
    "|------------|---------|--------|---------|------------------|\n",
    "| origianl imbalanced data      |  66.51%(±0.36) | 66.41%(±0.58) |  58.33%(±0.48) | 60.01%(±0.55) |\n",
    "| -oversampling- | | | | |\n",
    "|  RandomOverSampler      |  65.95%(±0.31) | 63.29%(±0.32) |  66.09%(±0.40) | 64.18%(±0.34) |\n",
    "|  SMOTE       |  66.03%(±0.36) | 63.34%(±0.40) |  65.94%(±0.47) | 64.21%(±0.43) |\n",
    "| -downsampling- | | | | |\n",
    "| RandomUnderSampler |  61.80%(±0.25) | 60.17%(±0.21) |  64.62%(±0.21) | 60.63%(±0.26) |\n",
    "| NaerMiss-1 |  60.11%(±0.24) | 58.64%(±0.28) |  62.99%(±0.32) | 58.51%(±0.25) |\n",
    "| NaerMiss-2 |  57.11%(±2.24) | 57.32%(±1.05) |  61.937%(±1.22) | 56.08%(±2.08) |\n",
    "| NaerMiss-3 |  61.03%(±0.20) | 59.12%(±0.23) |  63.20%(±0.39) | 59.83%(±0.21) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above result, the sampling technique I'll be using for the next post will be SMOTE. In the next post, I will try different classifiers with SMOTE oversampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
